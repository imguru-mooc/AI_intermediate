{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.9.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jikim\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 39 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이저 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 119, 102]\n",
      "['[ C L S ]', '안', '# # 녕', '# # 하', '# # 세', '# # 요', ',', '반', '# # 갑', '# # 습', '# # 니 다', '.', '[ S E P ]']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"안녕하세요, 반갑습니다.\"\n",
    "\n",
    "encode = tokenizer.encode(test_sentence)\n",
    "token_print = [tokenizer.decode(token) for token in encode]\n",
    "\n",
    "print(type(encode))\n",
    "print(encode)\n",
    "print(token_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다 [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다\")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "# [101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 102]\n",
    "print(eng_encode)\n",
    "# [101, 31178, 11356, 102]\n",
    "print(kor_decode)\n",
    "# [CLS] 안녕하세요, 반갑습니다 [SEP]\n",
    "print(eng_decode)\n",
    "# [CLS] Hello world [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Movie Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"naver_movie\", \"ratings_train.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"naver_movie\", \"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data = train_data.dropna()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] \n",
      " [100, 102, 0, 101, 103]\n",
      "[101, 9521, 118741, 35506, 24982, 48549, 117, 9321, 118610, 119081, 48345, 119, 102]\n",
      "[101, 31178, 11356, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다. [SEP]\n",
      "[CLS] Hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 스페셜 토큰\n",
    "print(tokenizer.all_special_tokens, \"\\n\", tokenizer.all_special_ids)\n",
    "\n",
    "# 토크나이저 테스트하기\n",
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다. \")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "print(eng_encode)\n",
    "print(kor_decode)\n",
    "print(eng_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "\n",
    "# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n",
    "\n",
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # Construct attn. masks.\n",
    "        \n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/149995 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████| 149995/149995 [00:26<00:00, 5596.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 149995, # labels: 149995\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data[:1000] # for test\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(train_data[\"document\"], train_data[\"label\"]), total=len(train_data)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass\n",
    "\n",
    "train_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "train_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_movie_inputs = (train_movie_input_ids, train_movie_attention_masks, train_movie_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_movie_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101   9519   9074 119005    119    119   9708 119235   9715 119230\n",
      "  16439  77884  48549   9284  22333  12692    102      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "<class 'numpy.int32'>\n",
      "101\n",
      "[ C L S ]\n",
      "['[ C L S ]', '아', '더', '# # 빙', '.', '.', '진', '# # 짜', '짜', '# # 증', '# # 나', '# # 네', '# # 요', '목', '# # 소', '# # 리', '[ S E P ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]', '[ P A D ]']\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이: 39\n",
    "input_id = train_movie_input_ids[0]\n",
    "attention_mask = train_movie_attention_masks[0]\n",
    "token_type_id = train_movie_type_ids[0]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))\n",
    "\n",
    "# a = np.array([1,2,3,4])\n",
    "# b = [data for data in a]\n",
    "# print(b)\n",
    "\n",
    "print(type(input_id[0]))\n",
    "print(input_id[0])\n",
    "print(tokenizer.decode(int(input_id[0])))\n",
    "token_print = [tokenizer.decode(int(token)) for token in input_id]\n",
    "print(token_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pytorch as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e8b13c963c4a9e97aa1b3ce0d154dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ebbb87a31441f796d9ccb554a76213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n",
    "                                                name=\"classifier\") # Weight (D,H) => (512,2) Bias (H,) => (2,)\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1] \n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비하기\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KOR\\tf2_bert_naver_movie -- Folder create complete \n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000028EFD32FFA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000028EFD32FFA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.7711WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "3750/3750 [==============================] - 796s 209ms/step - loss: 0.4611 - accuracy: 0.7711 - val_loss: 0.3397 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84823, saving model to data_out/KOR\\tf2_bert_naver_movie\\weights.h5\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 743s 198ms/step - loss: 0.3160 - accuracy: 0.8618 - val_loss: 0.3241 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84823 to 0.85980, saving model to data_out/KOR\\tf2_bert_naver_movie\\weights.h5\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 658s 176ms/step - loss: 0.2592 - accuracy: 0.8913 - val_loss: 0.3303 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.85980 to 0.86126, saving model to data_out/KOR\\tf2_bert_naver_movie\\weights.h5\n",
      "{'loss': [0.40681177377700806, 0.31583371758461, 0.26320981979370117], 'accuracy': [0.8099936842918396, 0.863078773021698, 0.8892713189125061], 'val_loss': [0.3396698236465454, 0.32412955164909363, 0.33029690384864807], 'val_accuracy': [0.8482282757759094, 0.859795331954956, 0.8612620234489441]}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_naver_movie\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = cls_model.fit(train_movie_inputs, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Movie Review Test 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "test_data = test_data.dropna()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "49997it [00:08, 5683.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sents, labels 49997, 49997\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent, test_label in tqdm(zip(test_data[\"document\"], test_data[\"label\"])):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        test_data_labels.append(test_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "\n",
    "test_movie_input_ids = np.array(input_ids, dtype=int)\n",
    "test_movie_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_movie_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_movie_inputs = (test_movie_input_ids, test_movie_attention_masks, test_movie_type_ids)\n",
    "\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(test_movie_input_ids), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 36s 746ms/step - loss: 0.3397 - accuracy: 0.8574\n",
      "test loss, test acc:  [0.3396869897842407, 0.8573914170265198]\n"
     ]
    }
   ],
   "source": [
    "cls_model.load_weights('weights.h5')\n",
    "results = cls_model.evaluate(test_movie_inputs, test_data_labels, batch_size=1024)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 예측하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9638, 42428, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# input_id, attention_mask, token_type_id = bert_tokenizer(\"화려한 그래픽 , 탄탄한 스토리 , 정말 재미 있어요\", MAX_LEN)\n",
    "# input_id, attention_mask, token_type_id = bert_tokenizer(\"시간 아까운 스토리\", MAX_LEN)\n",
    "# input_id, attention_mask, token_type_id = bert_tokenizer(\"배우들의 연기는 좋으나 스토리가 다소 빈약해요\", MAX_LEN)\n",
    "input_id, attention_mask, token_type_id = bert_tokenizer(\"이 영화 쥑이네\", MAX_LEN)\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "x = [np.array([input_id]),np.array([token_type_id]),np.array([attention_mask]) ]\n",
    "results = cls_model.predict(x)\n",
    "results = np.argmax(results)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
