{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "      outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (2.22.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.7.4.2)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: future in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.42.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.18.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (3.11.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (2.2.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow_datasets) (45.2.0.post20200210)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21498 sha256=4ac4d89f5577509ccc5e55e7cf2937dad2dfa20251ed5070d1583c96f0c79f85\n",
      "  Stored in directory: c:\\users\\jikim\\appdata\\local\\pip\\cache\\wheels\\29\\93\\c6\\762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "Successfully built promise\n",
      "Installing collected packages: importlib-resources, googleapis-common-protos, tensorflow-metadata, dill, promise, tensorflow-datasets\n",
      "Successfully installed dill-0.3.3 googleapis-common-protos-1.52.0 importlib-resources-3.3.0 promise-2.3 tensorflow-datasets-4.1.0 tensorflow-metadata-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8180, 256)\n",
      "(1, 8180, 256)\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 1.4557 - accuracy: 0.0232\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 248s 1s/step - loss: 1.1820 - accuracy: 0.0494\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 1.0036 - accuracy: 0.0508\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 246s 1s/step - loss: 0.9281 - accuracy: 0.0543\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 241s 1s/step - loss: 0.8711 - accuracy: 0.0575\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 241s 1s/step - loss: 0.8114 - accuracy: 0.0617\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 0.7457 - accuracy: 0.0674\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 267s 1s/step - loss: 0.6729 - accuracy: 0.0751\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 285s 2s/step - loss: 0.5937 - accuracy: 0.0840\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 275s 1s/step - loss: 0.5113 - accuracy: 0.0930\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 260s 1s/step - loss: 0.4283 - accuracy: 0.1037\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 239s 1s/step - loss: 0.3458 - accuracy: 0.1150\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 0.2720 - accuracy: 0.1257\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 236s 1s/step - loss: 0.2062 - accuracy: 0.1362\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 223s 1s/step - loss: 0.1512 - accuracy: 0.1455\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.1106 - accuracy: 0.1530\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0793 - accuracy: 0.1590\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0615 - accuracy: 0.1618\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.0508 - accuracy: 0.1635\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 224s 1s/step - loss: 0.0454 - accuracy: 0.1645\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0415 - accuracy: 0.1651\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 225s 1s/step - loss: 0.0400 - accuracy: 0.1654\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.0362 - accuracy: 0.1663\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0309 - accuracy: 0.1673\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0271 - accuracy: 0.1683\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0246 - accuracy: 0.1690\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0221 - accuracy: 0.1696\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 218s 1s/step - loss: 0.0200 - accuracy: 0.1702\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0184 - accuracy: 0.1705\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0164 - accuracy: 0.1711\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0151 - accuracy: 0.1714\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0139 - accuracy: 0.1717\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0130 - accuracy: 0.1719\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0118 - accuracy: 0.1723\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0117 - accuracy: 0.1722\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0105 - accuracy: 0.1725\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 224s 1s/step - loss: 0.0102 - accuracy: 0.1725\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 233s 1s/step - loss: 0.0094 - accuracy: 0.1728\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 279s 2s/step - loss: 0.0090 - accuracy: 0.1730\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 0.0088 - accuracy: 0.1731\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 276s 1s/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 280s 2s/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 270s 1s/step - loss: 0.0074 - accuracy: 0.1733\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 249s 1s/step - loss: 0.0073 - accuracy: 0.1733\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 306s 2s/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 296s 2s/step - loss: 0.0067 - accuracy: 0.1735\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 301s 2s/step - loss: 0.0061 - accuracy: 0.1736\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 293s 2s/step - loss: 0.0062 - accuracy: 0.1735\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 273s 1s/step - loss: 0.0058 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 0.0059 - accuracy: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x214162e6808>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 영화 볼래?\n",
      "Output: 네 말씀해주세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"영화 볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 저는 고민이 없어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 카페갈래?\n",
      "Output: 카페 데이트 좋죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하고싶당\n",
      "Output: 그럴 땐 생각을 덜어봐요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하자\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
