{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [6.]\n",
      " [7.]\n",
      " [8.]\n",
      " [9.]]\n",
      "[[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]]\n",
      "tf.Tensor([[0. 0. 2. 2. 4. 4. 6. 6. 8. 8.]], shape=(1, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.0000000e+00 1.0000000e+00 1.5848932e-01 1.5848932e-01 2.5118861e-02\n",
      "  2.5118861e-02 3.9810711e-03 3.9810711e-03 6.3095731e-04 6.3095731e-04]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "position=10\n",
    "d_model=10\n",
    "\n",
    "position = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
    "print(position.numpy())\n",
    "\n",
    "i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "print(i.numpy())\n",
    "\n",
    "print(2 * (i // 2))\n",
    "\n",
    "angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "print(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "angle = 0\n",
    "radian = angle*np.pi/180\n",
    "temp = np.sin(radian)\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84147098 0.00999983] [0.54030231 0.99995   ]\n"
     ]
    }
   ],
   "source": [
    "radian = np.array([1,1,0.01,0.01])\n",
    "sines = np.sin(radian[0::2])\n",
    "cosines = np.cos(radian[1::2])\n",
    "print(sines, cosines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_angles( position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "position=5\n",
    "d_model=4\n",
    "\n",
    "angle_rads = get_angles(\n",
    "    position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "    i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "    d_model=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "#         print(pos_encoding.shape)\n",
    "#         print(pos_encoding[0,49])\n",
    "#         print(pos_encoding[0,48])\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "(2, 2, 3)\n",
      "[[[ 3  4  5]\n",
      "  [ 9 14 19]]\n",
      "\n",
      " [[15 24 33]\n",
      "  [21 34 47]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(8).reshape(2,2,2)\n",
    "print(x)\n",
    "w = np.arange(6).reshape(2,3)\n",
    "print(w)\n",
    "out = np.dot(x,w)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)  (1,3,128)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)    (1,3,128)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)  (1,3,128)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query) # dot(query, Wq)\n",
    "        key = self.key_dense(key)       # dot(key,  Wk)\n",
    "        value = self.value_dense(value) # dot(value, Wv)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 객체를 함수처럼 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foo.__init__()\n",
      "Foo.__call__()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Foo:\n",
    "    def __init__(self):\n",
    "        print(\"Foo.__init__()\")\n",
    "        \n",
    "    def __call__(self):\n",
    "        print(\"Foo.__call__()\")\n",
    "        return 10\n",
    "        \n",
    "f = Foo()()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "      outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "      )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                  d_model, num_heads, dropout,\n",
    "                  name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9000, 128)\n",
      "(1, 9000, 128)\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "small_transformer = transformer(\n",
    "    vocab_size = 9000,\n",
    "    num_layers = 4,\n",
    "    dff = 512,\n",
    "    d_model = 128,\n",
    "    num_heads = 4,\n",
    "    dropout = 0.3,\n",
    "    name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "# Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.1.0-py3-none-any.whl (3.6 MB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (2.22.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.7.4.2)\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.25.0-py3-none-any.whl (44 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: future in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.18.2)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.42.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (1.18.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow_datasets) (3.11.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jikim\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (2.2.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jikim\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow_datasets) (45.2.0.post20200210)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21498 sha256=4ac4d89f5577509ccc5e55e7cf2937dad2dfa20251ed5070d1583c96f0c79f85\n",
      "  Stored in directory: c:\\users\\jikim\\appdata\\local\\pip\\cache\\wheels\\29\\93\\c6\\762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "Successfully built promise\n",
      "Installing collected packages: importlib-resources, googleapis-common-protos, tensorflow-metadata, dill, promise, tensorflow-datasets\n",
      "Successfully installed dill-0.3.3 googleapis-common-protos-1.52.0 importlib-resources-3.3.0 promise-2.3 tensorflow-datasets-4.1.0 tensorflow-metadata-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8180, 256)\n",
      "(1, 8180, 256)\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 1.4557 - accuracy: 0.0232\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 248s 1s/step - loss: 1.1820 - accuracy: 0.0494\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 1.0036 - accuracy: 0.0508\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 246s 1s/step - loss: 0.9281 - accuracy: 0.0543\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 241s 1s/step - loss: 0.8711 - accuracy: 0.0575\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 241s 1s/step - loss: 0.8114 - accuracy: 0.0617\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 0.7457 - accuracy: 0.0674\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 267s 1s/step - loss: 0.6729 - accuracy: 0.0751\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 285s 2s/step - loss: 0.5937 - accuracy: 0.0840\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 275s 1s/step - loss: 0.5113 - accuracy: 0.0930\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 260s 1s/step - loss: 0.4283 - accuracy: 0.1037\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 239s 1s/step - loss: 0.3458 - accuracy: 0.1150\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 245s 1s/step - loss: 0.2720 - accuracy: 0.1257\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 236s 1s/step - loss: 0.2062 - accuracy: 0.1362\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 223s 1s/step - loss: 0.1512 - accuracy: 0.1455\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.1106 - accuracy: 0.1530\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0793 - accuracy: 0.1590\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0615 - accuracy: 0.1618\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.0508 - accuracy: 0.1635\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 224s 1s/step - loss: 0.0454 - accuracy: 0.1645\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0415 - accuracy: 0.1651\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 225s 1s/step - loss: 0.0400 - accuracy: 0.1654\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 222s 1s/step - loss: 0.0362 - accuracy: 0.1663\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0309 - accuracy: 0.1673\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0271 - accuracy: 0.1683\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0246 - accuracy: 0.1690\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0221 - accuracy: 0.1696\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 218s 1s/step - loss: 0.0200 - accuracy: 0.1702\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0184 - accuracy: 0.1705\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0164 - accuracy: 0.1711\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0151 - accuracy: 0.1714\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0139 - accuracy: 0.1717\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0130 - accuracy: 0.1719\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0118 - accuracy: 0.1723\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 220s 1s/step - loss: 0.0117 - accuracy: 0.1722\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 221s 1s/step - loss: 0.0105 - accuracy: 0.1725\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 224s 1s/step - loss: 0.0102 - accuracy: 0.1725\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 233s 1s/step - loss: 0.0094 - accuracy: 0.1728\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 279s 2s/step - loss: 0.0090 - accuracy: 0.1730\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 0.0088 - accuracy: 0.1731\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 276s 1s/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 280s 2s/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 270s 1s/step - loss: 0.0074 - accuracy: 0.1733\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 249s 1s/step - loss: 0.0073 - accuracy: 0.1733\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 306s 2s/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 296s 2s/step - loss: 0.0067 - accuracy: 0.1735\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 301s 2s/step - loss: 0.0061 - accuracy: 0.1736\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 293s 2s/step - loss: 0.0062 - accuracy: 0.1735\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 273s 1s/step - loss: 0.0058 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 268s 1s/step - loss: 0.0059 - accuracy: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x214162e6808>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 영화 볼래?\n",
      "Output: 네 말씀해주세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"영화 볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 저는 고민이 없어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 카페갈래?\n",
      "Output: 카페 데이트 좋죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하고싶당\n",
      "Output: 그럴 땐 생각을 덜어봐요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하자\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
