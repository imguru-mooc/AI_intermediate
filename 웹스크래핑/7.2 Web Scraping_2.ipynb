{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector 활용하기 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<img alt=\"Seoul-metro-2009-20180916-103548.jpg\" data-file-height=\"2403\" data-file-width=\"4272\" decoding=\"async\" height=\"169\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/300px-Seoul-metro-2009-20180916-103548.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/450px-Seoul-metro-2009-20180916-103548.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/600px-Seoul-metro-2009-20180916-103548.jpg 2x\" width=\"300\"/>]\n",
      "\n",
      "\n",
      "<img alt=\"Seoul-metro-2009-20180916-103548.jpg\" data-file-height=\"2403\" data-file-width=\"4272\" decoding=\"async\" height=\"169\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/300px-Seoul-metro-2009-20180916-103548.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/450px-Seoul-metro-2009-20180916-103548.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/600px-Seoul-metro-2009-20180916-103548.jpg 2x\" width=\"300\"/>\n",
      "\n",
      "\n",
      "[<img alt=\"Seoul-metro-2009-20180916-103548.jpg\" data-file-height=\"2403\" data-file-width=\"4272\" decoding=\"async\" height=\"169\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/300px-Seoul-metro-2009-20180916-103548.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/450px-Seoul-metro-2009-20180916-103548.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Seoul-metro-2009-20180916-103548.jpg/600px-Seoul-metro-2009-20180916-103548.jpg 2x\" width=\"300\"/>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Seoul_Metropolitan_Subway\"\n",
    "resp = requests.get(url)\n",
    "html_src = resp.text\n",
    "soup = BeautifulSoup(html_src, 'html.parser')\n",
    "\n",
    "\n",
    "subway_image = soup.select('#mw-content-text > div.mw-parser-output > table:nth-child(4) > tbody > tr:nth-child(1) > td > a > img')\n",
    "print(subway_image)\n",
    "print(\"\\n\")\n",
    "print(subway_image[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "subway_image2 = soup.select('tr > td > a > img')\n",
    "print(subway_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selector 활용하기 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1209\n",
      "\n",
      "\n",
      "[<a id=\"top\"></a>, <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>, <a class=\"mw-jump-link\" href=\"#searchInput\">Jump to search</a>]\n",
      "\n",
      "\n",
      "[<a class=\"external text\" href=\"https://deepl.com\" rel=\"nofollow\">DeepL</a>, <a class=\"external text\" href=\"https://translate.google.com/\" rel=\"nofollow\">Google Translate</a>, <a class=\"external text\" href=\"http://www.seoulmetro.co.kr/kr/board.do?menuIdx=548\" rel=\"nofollow\">\"자료실 : 알림마당&gt;자료실&gt;자료실\"</a>]\n",
      "\n",
      "\n",
      "[<div id=\"siteNotice\"><!-- CentralNotice --></div>]\n",
      "\n",
      "\n",
      "[<div id=\"siteNotice\"><!-- CentralNotice --></div>]\n",
      "\n",
      "\n",
      "[]\n",
      "\n",
      "\n",
      "[<span class=\"mw-headline\" id=\"Overview\">Overview</span>, <span class=\"mw-headline\" id=\"History\">History</span>, <span class=\"mw-headline\" id=\"Lines_and_branches\">Lines and branches</span>, <span class=\"mw-headline\" id=\"Rolling_stock\">Rolling stock</span>, <span class=\"mw-headline\" id=\"Fares_and_ticketing\">Fares and ticketing</span>, <span class=\"mw-headline\" id=\"Current_construction\">Current construction</span>, <span class=\"mw-headline\" id=\"Opening_2021\">Opening 2021</span>, <span class=\"mw-headline\" id=\"Opening_2022\">Opening 2022</span>, <span class=\"mw-headline\" id=\"Opening_2023\">Opening 2023</span>, <span class=\"mw-headline\" id=\"Opening_2024+\">Opening 2024+</span>, <span class=\"mw-headline\" id=\"Approved_for_construction\">Approved for construction</span>, <span class=\"mw-headline\" id=\"Planned\">Planned</span>, <span class=\"mw-headline\" id=\"Seoul_City\">Seoul City</span>, <span class=\"mw-headline\" id=\"Incheon_City\">Incheon City</span>, <span class=\"mw-headline\" id=\"Network_map\">Network map</span>, <span class=\"mw-headline\" id=\"See_also\">See also</span>, <span class=\"mw-headline\" id=\"Notes\">Notes</span>, <span class=\"mw-headline\" id=\"References\">References</span>, <span class=\"mw-headline\" id=\"External_links\">External links</span>]\n",
      "\n",
      "\n",
      "[<span class=\"mw-headline\" id=\"Overview\">Overview</span>, <span class=\"mw-headline\" id=\"History\">History</span>, <span class=\"mw-headline\" id=\"Lines_and_branches\">Lines and branches</span>, <span class=\"mw-headline\" id=\"Rolling_stock\">Rolling stock</span>, <span class=\"mw-headline\" id=\"Fares_and_ticketing\">Fares and ticketing</span>, <span class=\"mw-headline\" id=\"Current_construction\">Current construction</span>, <span class=\"mw-headline\" id=\"Opening_2021\">Opening 2021</span>, <span class=\"mw-headline\" id=\"Opening_2022\">Opening 2022</span>, <span class=\"mw-headline\" id=\"Opening_2023\">Opening 2023</span>, <span class=\"mw-headline\" id=\"Opening_2024+\">Opening 2024+</span>, <span class=\"mw-headline\" id=\"Approved_for_construction\">Approved for construction</span>, <span class=\"mw-headline\" id=\"Planned\">Planned</span>, <span class=\"mw-headline\" id=\"Seoul_City\">Seoul City</span>, <span class=\"mw-headline\" id=\"Incheon_City\">Incheon City</span>, <span class=\"mw-headline\" id=\"Network_map\">Network map</span>, <span class=\"mw-headline\" id=\"See_also\">See also</span>, <span class=\"mw-headline\" id=\"Notes\">Notes</span>, <span class=\"mw-headline\" id=\"References\">References</span>, <span class=\"mw-headline\" id=\"External_links\">External links</span>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Seoul_Metropolitan_Subway\"\n",
    "resp = requests.get(url)\n",
    "html_src = resp.text\n",
    "soup = BeautifulSoup(html_src, 'html.parser')\n",
    "                 \n",
    "links = soup.select('a')\n",
    "print(len(links))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(links[:3])\n",
    "print(\"\\n\")\n",
    "\n",
    "external_links = soup.select('a[class=\"external text\"]')\n",
    "print(external_links[:3])\n",
    "print(\"\\n\")\n",
    "\n",
    "id_selector = soup.select('#siteNotice')\n",
    "print(id_selector)\n",
    "print(\"\\n\")\n",
    "\n",
    "id_selector2 = soup.select('div#siteNotice')\n",
    "print(id_selector2)\n",
    "print(\"\\n\")\n",
    "\n",
    "id_selector3 = soup.select('p#siteNotice')\n",
    "print(id_selector3)\n",
    "print(\"\\n\")\n",
    "\n",
    "class_selector = soup.select('.mw-headline')\n",
    "print(class_selector)\n",
    "print(\"\\n\")\n",
    "\n",
    "class_selector2 = soup.select('span.mw-headline')\n",
    "print(class_selector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구글 뉴스 클리핑하기 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔 ICT기업 루넷, 파이썬 플랫폼 프로젝트 계약 체결\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://news.google.com\"\n",
    "search_url = base_url + \"/search?q=%ED%8C%8C%EC%9D%B4%EC%8D%AC&hl=ko&gl=KR&ceid=KR%3Ako\"\n",
    "resp = requests.get(search_url)\n",
    "html_src = resp.text\n",
    "soup = BeautifulSoup(html_src, 'html.parser')\n",
    "\n",
    "news_items = soup.select('div[class=\"xrnccd\"]')\n",
    "# print(len(news_items))\n",
    "# print(news_items[0])\n",
    "# print(\"\\n\")\n",
    "\n",
    "# for item in news_items[:1]:\n",
    "#     link = item.find('a', attrs={'class':'VDXfz'}).get('href')\n",
    "#     news_link = base_url + link[1:]\n",
    "#     print(news_link)\n",
    "    \n",
    "#     news_title = item.find('a', attrs={'class':'DY5T1d'}).getText()\n",
    "#     print(news_title)\n",
    "\n",
    "# #     news_content = item.find('span', attrs={'class':'xBbh9'}).text\n",
    "# #     print(news_content)\n",
    "\n",
    "#     news_agency = item.find('a', attrs={'class':'wEwyrc AVN2gc uQIVzc Sksgp'}).text\n",
    "#     print(news_agency)\n",
    "\n",
    "#     news_reporting = item.find('time', attrs={'class':'WW6dff uQIVzc Sksgp'})\n",
    "#     news_reporting_datetime = news_reporting.get('datetime').split('T')\n",
    "#     news_reporting_date = news_reporting_datetime[0]\n",
    "#     news_reporting_time = news_reporting_datetime[1][:-1]\n",
    "#     print(news_reporting_date, news_reporting_time)    \n",
    "#     print(\"\\n\")\n",
    "    \n",
    "def google_news_clipping(url, limit=5):\n",
    "    resp = requests.get(url)\n",
    "    html_src = resp.text\n",
    "    soup = BeautifulSoup(html_src, 'html.parser')\n",
    "    \n",
    "    news_items = soup.select('div[class=\"xrnccd\"]')\n",
    "    \n",
    "    links=[]; titles=[]; contents=[]; agencies=[]; reporting_dates=[]; reporting_times=[];\n",
    "    \n",
    "    for item in news_items[:limit]:\n",
    "        link = item.find('a', attrs={'class':'VDXfz'}).get('href')\n",
    "        news_link = base_url + link[1:]\n",
    "        links.append(news_link)\n",
    "        \n",
    "        news_title = item.find('a', attrs={'class':'DY5T1d'}).getText()\n",
    "        titles.append(news_title)\n",
    "    \n",
    "#         news_content = item.find('span', attrs={'class':'xBbh9'}).text\n",
    "#         contents.append(news_content)\n",
    "    \n",
    "        news_agency = item.find('a', attrs={'class':'wEwyrc AVN2gc uQIVzc Sksgp'}).text\n",
    "        agencies.append(news_agency)\n",
    "    \n",
    "        news_reporting = item.find('time', attrs={'class':'WW6dff uQIVzc Sksgp'})\n",
    "        news_reporting_datetime = news_reporting.get('datetime').split('T')\n",
    "        news_reporting_date = news_reporting_datetime[0]\n",
    "        news_reporting_time = news_reporting_datetime[1][:-1]\n",
    "        reporting_dates.append(news_reporting_date)\n",
    "        reporting_times.append(news_reporting_time)     \n",
    "    \n",
    "    result = {'link':links, 'title':titles, 'agency':agencies, \\\n",
    "              'date':reporting_dates, 'time':reporting_times}\n",
    "    \n",
    "    return result\n",
    "\n",
    "news = google_news_clipping(search_url, 5)\n",
    "print(news['title'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구글 뉴스 클리핑하기 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요: 테슬라\n",
      "['https://news.google.com/articles/CBMiSmh0dHBzOi8vYml6LmNob3N1bi5jb20vaW5kdXN0cnkvY2FyLzIwMjEvMTAvMjkvNU0zU0ZHWjNJQkhRM0c0NFZGRDZDSkxLVVUv0gFZaHR0cHM6Ly9iaXouY2hvc3VuLmNvbS9pbmR1c3RyeS9jYXIvMjAyMS8xMC8yOS81TTNTRkdaM0lCSFEzRzQ0VkZENkNKTEtVVS8_b3V0cHV0VHlwZT1hbXA?hl=ko&gl=KR&ceid=KR%3Ako', 'https://news.google.com/articles/CBMiOmh0dHBzOi8vd3d3LmhhbmkuY28ua3IvYXJ0aS9lY29ub215L21hcmtldGluZy8xMDE2NDIzLmh0bWzSAQA?hl=ko&gl=KR&ceid=KR%3Ako']\n",
      "['조선비즈', '한겨레']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "# keyword_input = '파이썬'\n",
    "# keyword = urllib.parse.quote(keyword_input)\n",
    "# print('파이썬 문자열을 URL 코드로 변환: ', keyword)\n",
    "\n",
    "# base_url = \"https://news.google.com\"\n",
    "# search_url = base_url + \"/search?q=\" + keyword + \"&hl=ko&gl=KR&ceid=KR%3Ako\"\n",
    "# print('검색어와 조합한 URL: ', search_url)\n",
    "\n",
    "def google_news_clipping_keyword(keyword_input, limit=5):\n",
    "    \n",
    "    keyword = urllib.parse.quote(keyword_input)\n",
    "    \n",
    "    url = base_url + \"/search?q=\" + keyword + \"&hl=ko&gl=KR&ceid=KR%3Ako\"\n",
    "    \n",
    "    resp = requests.get(url)\n",
    "    html_src = resp.text\n",
    "    soup = BeautifulSoup(html_src, 'html.parser')\n",
    "    \n",
    "    news_items = soup.select('div[class=\"xrnccd\"]')\n",
    "    links=[]; titles=[]; contents=[]; agencies=[]; reporting_dates=[]; reporting_times=[];\n",
    "    \n",
    "    for item in news_items[:limit]:\n",
    "        link = item.find('a', attrs={'class':'VDXfz'}).get('href')\n",
    "        news_link = base_url + link[1:]\n",
    "        links.append(news_link)\n",
    "        \n",
    "        news_title = item.find('a', attrs={'class':'DY5T1d'}).getText()\n",
    "        titles.append(news_title)\n",
    "    \n",
    "#         news_content = item.find('span', attrs={'class':'xBbh9'}).text\n",
    "#         contents.append(news_content)\n",
    "    \n",
    "        news_agency = item.find('a', attrs={'class':'wEwyrc AVN2gc uQIVzc Sksgp'}).text\n",
    "        agencies.append(news_agency)\n",
    "    \n",
    "        news_reporting = item.find('time', attrs={'class':'WW6dff uQIVzc Sksgp'})\n",
    "        news_reporting_datetime = news_reporting.get('datetime').split('T')\n",
    "        news_reporting_date = news_reporting_datetime[0]\n",
    "        news_reporting_time = news_reporting_datetime[1][:-1]\n",
    "        reporting_dates.append(news_reporting_date)\n",
    "        reporting_times.append(news_reporting_time)     \n",
    "    \n",
    "    result = {'link':links, 'title':titles, 'agency':agencies, \\\n",
    "              'date':reporting_dates, 'time':reporting_times}\n",
    "    \n",
    "    return result\n",
    "\n",
    "search_word = input(\"검색어를 입력하세요: \")\n",
    "news = google_news_clipping_keyword(search_word, 2)\n",
    "print(news['link'])\n",
    "print(news['agency'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
